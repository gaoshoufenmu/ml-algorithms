上一篇文章中，我们知道了梯度下降法求解目标函数的最小值，以及给出了迭代公式，然而迭代$$T$$ 次后到底离目标函数真正的最小值还差多少？本篇文章我们将来分析这个问题。

设目标函数$$f(\mathbf w)$$ 在$$\mathbf w^*$$ 处取得最小值，梯度下降法迭代$$T$$ 次后的输出为$$\overline {\mathbf w} = \frac 1 T \sum_{t=1}^T \mathbf w^{(t)}$$，于是，



