隐马尔可夫模型上一章节已经介绍过了，这里直接研究其相关的三个基本问题。

* 模型参数

$$\lambda = [\mathbf A, \mathbf B, \pi]$$

* 观测序列

$$O = (o_1,o_2,...,o_n)$$

* 状态序列

$$I = (i_1,i_2,...,i_n)$$

### 概率计算

给定$$\lambda, \ O$$，计算$$O$$ 出现的概率。

#### 直接计算

$$P(O|\lambda) = \sum_I \ P(O,I|\lambda) = P(O|I, \lambda)P(I|\lambda)$$                                                                        \(1\)

假设是一阶的，每个状态仅与前一状态相关，于是状态序列的概率为，

$$P(I|\lambda) = \pi_{i_1}a_{i_1i_2} \cdot \cdot \cdot a_{i_{n-1}i_n}$$                                                                                                          \(2\)

因为假设当前观测仅与当前状态相关，根据发射概率矩阵可知，

$$P(O|I,\lambda) = b_{i_1o_1}b_{i_2o_2} \cdot \cdot \cdot b_{i_no_n}$$                                                                                                      \(3\)

联立以上三式，

$$P(O|\lambda) = \sum_I \pi_{i_1} b{i_1o_1}a_{i_1i_2}b_{i_2o_2} \cdot \cdot \cdot a_{i_{n-1}i_n}b_{i_no_n}$$                                                                        \(4\)

然而上述公式通常计算量很大，通常不为我们所考虑。

#### 前向算法

其实如果真要去计算\(4\)式，会发现有很多重复的部分，或者说有很多中间结果，如果能保存下来，则会大大提高效率，比如在$$t$$ 时刻观测值为$$o_t$$，无论当前状态$$i_t$$ 是什么，按照\(4\)式，之前的从时刻$$1$$ 到时刻$$t-1$$ 的所有状态组合都要再计算一次，显然这是重复的，没必要的。

我们思考一下就会发现，每个时刻$$t$$ 均可能有$$N$$ 个状态，每个时刻的状态仅依赖与前一时刻的状态，而每个前一时刻同样可能有$$N$$ 个状态，然后分别再继续依赖前前一时刻的$$N$$ 种状态，如此下去直到时刻$$1$$。反过来想，如果知道时刻$$t$$ 状态为$$i_t$$ 的概率（时刻$$1$$ 到时刻$$t-1$$ 的状态是任意的），就可以计算时刻$$t+1$$ 状态为$$i_{t+1}$$ 的概率了（时刻$$1$$ 到时刻$$t$$ 的状态是任意的），如下图示意，

![](/assets/HMM_forward.png)

定义，时刻$$t$$ 状态为$$i_t$$ 已知观测序列为$$(o_1,o_2,...,o_t)$$ 的概率为**前向概率**，

$$\alpha_t (i_t) = P(o_1,o_2,...,o_t,i_t)$$                                                                                                                \(5\)

于是迭代公式为，

$$\alpha_{t+1} (i_{t+1}) = P(o_1,o_2,...,o_t,o_{t+1}, i_{t+1}) = \sum_{i_t=1}^N P(o_1,o_2,...,o_t,i_t, o_{t+1}, i_{t+1}) = \sum_{i_t=1}^N \alpha_t (i_t) a_{i_t i_{t+1}} b_{i_{t+1}o_{t+1}}$$  \(6\)

特殊地，

$$\alpha_1 (i_1) = \pi_{i1} b_{i_1o_1}$$                                                                                                                                   \(6\)

于是，

$$P(O|\lambda) = \sum_{i_n=1}^N \alpha_n(i_n)$$                                                                                                                     \(7\)

#### 后向算法

与前向算法类似，直接给出相关定义和公式。

定义，时刻$$t$$ 状态为$$i_t$$ 已知观测序列为$$(o_{t+1},o_{t+2}, ..., o_n)$$ 的概率为**后向概率**，

$$\beta_t(i_t) = P(o_{t+1}, o_{t+2}, ..., o_n, i_t)$$                                                                                                       \(8\)

迭代公式为，

$$\beta_{t-1} (i_{t-1}) = P(o_t, o_{t+1}, ..., o_n, i_{t-1}) = \sum_{i_t = i}^N P(o_{t+1}, ..., o_n, i_t, o_t, i_{t-1}) = \sum_{i_t=1}^N  a_{i_{t-1} i_t}b_{i_to_t} \beta_t (i_t)$$          \(9\)

特殊地，

$$\beta_n(i_n) = 1$$                                                                                                                                                 \(10\)

于是，

$$P(O|\lambda) = \sum_{i_1=1}^N \pi_{i_1}\beta_1(i_1) b_{i_1o_1}$$                                                                                                            \(11\)

#### 前向后向算法

* 给定模型参数$$\lambda$$ 和观测序列$$O$$，在时刻$$t$$ 状态为$$i_t$$ 的条件概率为，

$$\gamma_t(i_t) = P(i_t|O, \lambda) = P(i_t, O|\lambda) / P(O|\lambda)$$

根据前向概率和后向概率可知$$t$$ 时刻状态为$$i_t$$ 且观测序列为$$O$$ 的概率为，

$$P(i_t,O|\lambda) = \alpha_t(i_t) \beta_t(i_t)$$

对$$t$$ 时刻的状态求累加和得到观测序列出现的概率，

$$P(O|\lambda) = \sum_{i_t=1}^N P(i_t,O|\lambda)$$

综上，

$$\gamma_t(i_t) = \alpha_t(i_t) \beta_t(i_t) / \sum_{i=1}^N \alpha_t(i) \beta_t(i)$$                                                                                               \(12\)

* 给定模型参数$$\lambda$$ 和观测序列$$O$$，在时刻$$t$$ 状态为$$i_t$$ 且$$t+1$$ 时刻状态为$$i_{t+1}$$ 的条件概率为

$$\xi(i_t,i_{t+1}) = P(i_t, i_{t+1}|O, \lambda) = P(i_t, i_{t+1},O|\lambda) / P(O|\lambda) = P(i_t, i_{t+1},O|\lambda) / \sum_{i=1}^N \sum_{j=1}^N P(i, j,O|\lambda)$$

根据前向概率和后向概率，

$$P(i,j,O|\lambda) = \alpha_t(i) a_{ij} b_{jo_{t+1}} \beta_{t+1}(j)$$

于是，

$$\xi(i_t,i_{t+1}) = \alpha_t(i_t) a_{i_t i_{t+1}} b_{i_{t+1}o_{t+1}} \beta_{t+1}(i_{t+1}) / \sum_{i=1}^N \sum_{j=1}^N \alpha_t(i) a_{ij} b_{jo_{t+1}} \beta_{t+1}(j)$$

